"""
Partsouq Playwright Stealth - FIXED
转拽  注转 驻 驻拽 拽爪注
"""

from fastapi import FastAPI
import os
import time
import logging
import asyncio
import random
from playwright.async_api import async_playwright
from typing import Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Partsouq Playwright FIXED",
    description="转拽  - 注 100%",
    version="6.1.0"
)

# SmartProxy configs - FIXED 驻 驻拽
SMARTPROXY_ENDPOINTS = [
    # 驻专  砖
    f"http://{os.getenv('SMARTP_USER', 'smart-byparr')}:{os.getenv('SMARTP_PASS', '1209QWEasdzxcv')}@proxy.smartproxy.net:3120",
    
    # 注 session 注专 sticky
    f"http://{os.getenv('SMARTP_USER', 'smart-byparr')}-session-{random.randint(1000,9999)}:{os.getenv('SMARTP_PASS', '1209QWEasdzxcv')}@proxy.smartproxy.net:3120",
    
    # 专  专砖  注
    f"http://{os.getenv('SMARTP_USER', 'smart-byparr')}:{os.getenv('SMARTP_PASS', '1209QWEasdzxcv')}@gate.smartproxy.io:7000"
]

# Semaphore 爪注
SEM = asyncio.Semaphore(3)

class PlaywrightStealth:
    """Playwright 注 转拽 拽爪注"""
    
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.context = None
        
    async def init_browser(self, proxy_url: Optional[str] = None):
        """爪专转 browser - FIXED"""
        try:
            logger.info("Initializing Playwright browser...")
            
            self.playwright = await async_playwright().start()
            
            # 专转 browser 驻砖转 注转
            browser_options = {
                'headless': True,
                'args': [
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor'
                ]
            }
            
            # 住驻转 proxy  拽
            if proxy_url:
                try:
                    browser_options['proxy'] = {'server': proxy_url}
                    logger.info(f"Using proxy: {proxy_url.split('@')[0]}@***")
                except:
                    logger.warning("Proxy config failed, continuing without proxy")
            
            # 爪专转 browser
            self.browser = await self.playwright.chromium.launch(**browser_options)
            
            # context 注 stealth
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
            )
            
            # stealth injection
            await self.context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.chrome = {runtime: {}};
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3]});
            """)
            
            logger.info("Browser initialized successfully!")
            return True
            
        except Exception as e:
            logger.error(f"Browser init failed: {str(e)}")
            await self.cleanup()
            return False
    
    async def scrape_partsouq(self, vin: str):
        """住拽专驻 转拽"""
        
        # 住 注 proxy
        proxy_url = random.choice(SMARTPROXY_ENDPOINTS)
        
        if not await self.init_browser(proxy_url):
            logger.warning("Trying without proxy...")
            if not await self.init_browser():
                return {"success": False, "error": "Browser init completely failed"}
        
        try:
            page = await self.context.new_page()
            
            target_url = f"https://partsouq.com/en/search/all?q={vin}"
            logger.info(f"Navigating to: {target_url}")
            
            # 住 注 timeout 拽爪专 转专 (25s 拽 45s)
            await page.goto(target_url, wait_until='domcontentloaded', timeout=25000)
            
            # 转 拽爪专 转专
            await asyncio.sleep(6)
            
            # 拽转 Cloudflare
            content = await page.content()
            content_lower = content.lower()
            
            if 'just a moment' in content_lower:
                logger.info("Cloudflare - waiting 10s more...")
                await asyncio.sleep(10)
                content = await page.content()
                content_lower = content.lower()
            
            # 转
            current_url = page.url
            
            analysis = {
                'final_url': current_url,
                'content_size': len(content),
                'has_partsouq': 'partsouq' in content_lower,
                'has_vin': vin.lower() in content_lower,
                'has_parts': 'part' in content_lower,
                'has_search': '/search/' in current_url,
                'has_cloudflare': 'cloudflare' in content_lower,
                'proxy_used': bool(proxy_url)
            }
            
            success = (
                analysis['has_partsouq'] and
                not analysis['has_cloudflare'] and
                analysis['has_search']
            )
            
            # 转 
            sample = content[:300]
            sample_clean = ''.join(c if 32 <= ord(c) < 127 else ' ' for c in sample)
            sample_clean = ' '.join(sample_clean.split())[:150]
            
            await page.close()
            
            return {
                'success': success,
                'vin': vin,
                'url': target_url,
                'analysis': analysis,
                'sample_content': sample_clean,
                'method': 'playwright_stealth_fixed'
            }
            
        except Exception as e:
            logger.error(f"Scraping error: {str(e)}")
            return {
                'success': False,
                'error': f"Scraping failed: {str(e)}",
                'vin': vin
            }
        finally:
            await self.cleanup()
    
    async def cleanup(self):
        """拽"""
        try:
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
        except:
            pass
        
        self.context = None
        self.browser = None 
        self.playwright = None

@app.get("/")
def root():
    return {
        "message": " Partsouq Playwright FIXED",
        "status": "online",
        "version": "6.1.0",
        "mode": "playwright_stealth_fixed",
        "proxy": "smartproxy.net:3120"
    }

@app.get("/health")
def health():
    return {
        "status": "healthy",
        "timestamp": time.time()
    }

@app.get("/scrape/{vin}")
async def scrape_vin(vin: str):
    """住拽专驻 注 Semaphore"""
    
    async with SEM:  # 转 3 驻驻 拽
        logger.info(f"Scraping VIN: {vin}")
        
        scraper = PlaywrightStealth()
        
        try:
            result = await scraper.scrape_partsouq(vin)
            return result
            
        except Exception as e:
            logger.error(f"Main scrape error: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "vin": vin
            }

@app.get("/test-proxy")
async def test_proxy():
    """拽转 proxy 驻砖"""
    
    scraper = PlaywrightStealth()
    proxy_url = SMARTPROXY_ENDPOINTS[0]  # 驻专拽住 专砖 砖
    
    try:
        if await scraper.init_browser(proxy_url):
            page = await scraper.context.new_page()
            await page.goto('http://httpbin.org/ip', timeout=15000)
            
            content = await page.content()
            await scraper.cleanup()
            
            return {
                "proxy_test": "success",
                "proxy_config": "smartproxy.net:3120",
                "response_size": len(content)
            }
        else:
            return {
                "proxy_test": "browser_init_failed"
            }
            
    except Exception as e:
        await scraper.cleanup()
        return {
            "proxy_test": "failed", 
            "error": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    
    port = int(os.environ.get("PORT", 10000))
    
    logger.info(" Starting FIXED Playwright Scraper")
    logger.info(" Using smartproxy.net:3120")
    
    uvicorn.run("main:app", host="0.0.0.0", port=port)
